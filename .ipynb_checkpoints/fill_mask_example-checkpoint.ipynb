{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "collected-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-latvia",
   "metadata": {},
   "source": [
    "# Upload del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hindu-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello caricato\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-italian-cased')\n",
    "model = BertForMaskedLM.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n",
    "model.eval()\n",
    "print('Modello caricato')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-border",
   "metadata": {},
   "source": [
    "# Definisci la frase da analizzare, utilizza [MASK] per la parola mascherata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vulnerable-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Il gatto dorme sul [MASK].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "average-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni per la parola mascherata nella frase Il gatto dorme sul [MASK].:\n",
      "  1. letto, probabilità: 25.08%\n",
      "  2. divano, probabilità: 7.63%\n",
      "  3. pavimento, probabilità: 7.48%\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "mask_positions = [i for i, token_id in enumerate(encoded_input[\"input_ids\"][0]) if token_id == tokenizer.mask_token_id]\n",
    "outputs = model(**encoded_input)\n",
    "predictions = outputs.logits\n",
    "probabilities = F.softmax(predictions, dim=-1)\n",
    "topk_values, topk_indices = torch.topk(probabilities, k=3, dim=-1)\n",
    "\n",
    "for pos in mask_positions:\n",
    "    print(f\"Predizioni per la parola mascherata nella frase {text}:\")\n",
    "    for i in range(3):\n",
    "        word = tokenizer.convert_ids_to_tokens([topk_indices[0, pos, i].item()])[0]\n",
    "        prob = topk_values[0, pos, i].item()\n",
    "        print(f\"  {i+1}. {word}, probabilità: {prob*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
